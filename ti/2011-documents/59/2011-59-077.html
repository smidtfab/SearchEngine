<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
            "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>Running experiments on Amazon Mechanical Turk
</TITLE>

<META http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<META name="GENERATOR" content="hevea 1.10+9 of 2008-12-17">
<STYLE type="text/css">
.footnotetext{margin:0ex; padding 0ex;}
DIV.footnotetext P{margin:0px; text-indent:1em;}
.thefootnotes{text-align:left;margin:0ex;}
.dt-thefootnotes{margin:0em;}
.dd-thefootnotes{margin:0em 0em 0em 2em;}
.footnoterule{margin:1em auto 1em 0px;width:50%;}
.caption{padding-left:2ex; padding-right:2ex; margin-left:auto; margin-right:auto}
.title{margin:2ex auto;text-align:center}
.center{text-align:center;margin-left:auto;margin-right:auto;}
.flushleft{text-align:left;margin-left:0ex;margin-right:auto;}
DIV TABLE{margin-left:inherit;margin-right:inherit;}
PRE{text-align:left;margin-left:0ex;margin-right:auto;}
BLOCKQUOTE{margin-left:4ex;margin-right:4ex;text-align:left;}
TD P{margin:0px;}
DIV.hangparas1 P{text-indent:-1em;padding-left:1em;}
DIV.hangparas2 P{text-indent:-1em;padding-left:1em;}
</STYLE>
<LINK REL=STYLESHEET type="text/css" HREF="../../jdm.css">
</HEAD>
<BODY >
<!--HEVEA command line is: hevea -fix -O /home/baron/jdm/jdm.hva jdm10630a -->
<!--CUT DEF section 1 --><P>
<A HREF="http://journal.sjdm.org">Judgment and Decision Making</A>, vol. 5, no. 5, August 2010, pp.
</P><TABLE CLASS="title"><TR><TD><H1 CLASS="titlemain">Running experiments on Amazon Mechanical Turk</H1><H3 CLASS="titlerest">Gabriele Paolacci<SUP><A NAME="text1" HREF="#note1">*</A></SUP><BR>
 Advanced School of Economics, Ca&#X2019; Foscari University of Venice <br><br>Jesse Chandler<BR>
 Woodrow Wilson School of Public and International
Affairs, Princeton University<BR><br>
Panagiotis G. Ipeirotis<BR>
 Leonard N. Stern School of Business, New York University</H3></TD></TR>
</TABLE><P>Although Mechanical Turk has recently become popular among social
scientists as a source of experimental data, doubts may linger about
the quality of data provided by subjects recruited from online
labor markets. We address these potential concerns by presenting new
demographic data about the Mechanical Turk subject population,
reviewing the strengths of Mechanical Turk relative to other online and
offline methods of recruiting subjects, and comparing the magnitude
of effects obtained using Mechanical Turk and traditional subject
pools. We further discuss some additional benefits such as the
possibility of longitudinal, cross cultural and prescreening designs,
and offer some advice on how to best manage a common subject pool.</P><P><BR>
Keywords: experimentation, online research
</P><!--TOC section Introduction-->
<H2 CLASS="section"><!--SEC ANCHOR --><A NAME="htoc1">1</A>&#XA0;&#XA0;Introduction</H2><!--SEC END --><P>Mechanical Turk started in 2005 as a service to &#X201C;crowd-source&#X201D; labor
intensive tasks and is now being used as a source of subjects for
experimental research (e.g. Eriksson &amp; Simpson, 2010; Alter et al.,
in press). However, a combination of unfamiliarity with what
online labor markets are (and how to use them), uncertainty about the
demographic characteristics of their participants and concerns about
data quality from this sample may make some researchers wary of using
Mechanical Turk to collect data. To address these concerns we report
demographic characteristics of Mechanical Turk workers, highlight some
of the unique practical and methodological strengths of Mechanical
Turk as a source of research subjects and compare classic judgment and
decision making effects in this population and more traditional
subject populations.</P><P>The article is organized as follows. In Section 2, we introduce the main
features of Mechanical Turk and demonstrate that the population of
Mechanical Turk is at least as representative of the U.S. population as
traditional subject pools. Further, we show that it is shifting to
include more international participants. In Section 3, we review the
logic underlying concerns with collecting data using Mechanical Turk
and present the strengths and potentials of Mechanical Turk relative to
other online and offline methods of recruiting subjects. In Section 4,
we present the results of a comparative study involving classic
experiments in judgment and decision-making; we found no differences in
the magnitude of effects obtained using Mechanical Turk and using
traditional subject pools. Section 5 concludes by offering some advice
on payment of individual subjects.</P><!--TOC section Amazon Mechanical Turk-->
<H2 CLASS="section"><!--SEC ANCHOR --><A NAME="htoc2">2</A>&#XA0;&#XA0;Amazon Mechanical Turk</H2><!--SEC END --><!--TOC subsection Mechanical Turk: The service-->
<H3 CLASS="subsection"><!--SEC ANCHOR --><A NAME="htoc3">2.1</A>&#XA0;&#XA0;Mechanical Turk: The service</H3><!--SEC END --><P>Mechanical Turk is a crowdsourcing web service that coordinates the
supply and the demand of tasks that require human intelligence to
complete. Mechanical Turk is named after an 18<SUP>th</SUP>
century chess playing &#X201C;automaton&#X201D; that was in fact operated by a
concealed person. It is an online labor market where employees (called
<I>workers</I>) are recruited by employers (called
<I>requesters</I>) for the execution of tasks (called <I>HIT</I>s,
acronym for Human Intelligence Tasks) in exchange for a wage (called a
<I>reward</I>). Both workers and requesters are anonymous although
responses by a unique worker can be linked through an ID provided by
Amazon. Requesters post HITs that are visible only to workers who meet
predefined criteria (e.g., country of residence or accuracy in
previously completed tasks). When workers access the website, they
find a list of tasks sortable according to various criteria, including
size of the reward and maximum time allotted for the
completion. Workers can read brief descriptions and see previews of
the tasks before accepting to work on them.</P><P>Tasks are typically simple enough to require only a few minutes to be
completed such as image tagging, audio transcriptions, and survey
completion. More complicated tasks are typically decomposed into series
of smaller tasks including the checking and validation of other
workers&#X2019; HITs. Once a worker has completed a task, the
requester who supplied that task can pay him. Rewards can be as low as
$0.01, and rarely exceed $1. Translated into an hourly wage, the
typical worker is willing to work for about $1.40 an hour (Horton &amp;
Chilton, in press). </P><P>A requester can reward good work with bonuses and punish poor quality
work by refusing payment or even blocking a worker from completing
future tasks. Requesters who fail to provide sufficient justification
for rejecting a HIT can be filtered out by a worker, preventing future
exploitation. Some may wonder about who is willing to work for so low
wages. With the goal of providing experimenters with a typology of the
recruitable workforce in Mechanical Turk, we now present the results of
a demographic survey conducted in February, 2010.</P><!--TOC subsection Demographics of Mechanical Turk-->
<H3 CLASS="subsection"><!--SEC ANCHOR --><A NAME="htoc4">2.2</A>&#XA0;&#XA0;Demographics of Mechanical Turk</H3><!--SEC END --><P>It is reasonable to assume that only those in poor countries would be
willing to work for such low wages. However, until recently,
Amazon.com was paying cash only to workers that had a bank account in
the U.S., with other workers paid with Amazon.com gift cards. This
policy discouraged workers from other countries, and past demographic
surveys found that 70&#X2013;80% of workers were from the United States and
that Mechanical Turk workers were relatively representative of the
population of U.S. Internet users (Ipeirotis, 2009; Ross et al.,
2010). Recently, however, the population dynamics on Mechanical Turk
have changed significantly, with a greater proportion of Indian
subjects in recent experiments (e.g. Eriksson &amp; Simpson, 2010),
suggesting the need for a fresh survey of the workers.</P><P>We collected demographics of 1,000 Mechanical Turk users. The survey was
conducted over a period of three weeks in February 2010. Each
respondent was paid $0.10 for participating in the survey, which
required 3 minutes on average to complete. This resulted in an hourly
average wage of $1.66, which is superior to the median reservation
wage of $1.38/hour (Horton &amp; Chilton, in press). Participants from 66
countries responded. The plurality of workers was from the United
States (47%), but with a significant number of workers from India
(34%). We will now present the demographics for American workers. A
more detailed breakdown of demographics (including tables and graphs
and an analysis for India-based workers) is presented by Ipeirotis
(2010).</P><P><I>Gender and age distribution. </I>Across U.S.-based workers, there
are significantly more females (64.85%) than males (35.15%). The
relative overabundance of women is consistent with research on
subjects recruited through the Internet (Gosling et al., 2004) and
may reflect women having greater access to computers (either at home or
at work) or gender differences in motivation. Workers who took part to
our survey were 36.0 years old on average (min = 18, max = 81, median =
33) and thus slightly younger then both the U.S. population as a whole
and the population of Internet users. </P><P><I>Education and income level</I>. In general, the (self-reported)
educational level of U.S. workers is higher than the general
population. This is partially explained by the younger age of
Mechanical Turk users but may also reflect higher education levels
among early adopters of technology. Despite being more educated,
Mechanical Turk workers report lower income. The shape of the
distribution roughly matches the income distribution in the general
U.S. population. However, it is noticeable that the income level of
U.S. workers on Mechanical Turk is shifted towards lower income levels
(U.S. Census, 2007). For example, while 45% of the U.S. Internet
population earns below $60K/yr, the corresponding percentage across
U.S.-based Mechanical Turk workers is 66.7%. (This finding is
consistent with the earlier surveys that compared income levels on
Mechanical Turk workers with income level of the general U.S.
population (Ipeirotis, 2009). We should note that, despite the
differences with the general population, on all of these demographic
variables, Internet subject populations tend to be closer to the
U.S. population as a whole than subjects recruited from traditional
university subject pools.</P><P><I>Motivation</I>. We asked respondents to report their motivations
to participate in Mechanical Turk by selecting from a set of
predefined options. Only 13.8% of the U.S.-based workers reported
that Mechanical Turk was their primary source of income. However,
61.4% reported that earning additional money was an important driver
of participation to the website. We should note though, that many
workers also participate to Mechanical Turk for non-monetary reasons,
such as entertainment (40.7%) and &#X201C;killing time&#X201D; (32.3%). In fact,
69.6% of the U.S.-based workers reported that they consider
Mechanical Turk is a fruitful way to spend free time (e.g., instead of
watching TV), a finding which is consistent with previous results
(Chandler &amp; Kapelner, 2010; Horton, Rand &amp; Zeckhauser, 2010).</P><P>Most workers spend a day or less per week working on Mechanical Turk,
and tend to complete 20&#X2013;100 HITs during this time. This generates a
relatively low income stream for Mechanical Turk work, which is often
less than $20 per week. However, there are a few prolific workers that
devote a significant amount of time and effort, completing thousands of
HITs, and claim to generate an income of more than $1000/month (for a
more detailed discussion see Ipeirotis, 2010). This reflects the
substantial number of subjects in the U.S. who use Mechanical Turk
as a supplementary source of income.</P><P>In sum, U.S. workers on Mechanical Turk are arguably closer to the U.S.
population as a whole than subjects recruited from traditional
university subject pools. Moreover, the increasing diversity of workers
on Mechanical Turk makes it easy to conduct cross-cultural studies of
decision making (e.g., Eriksson &amp; Simpson, 2010). Note that Amazon
allows participation in a given HIT to be restricted to workers from a
specific country, allowing researchers to maintain a homogeneous
population despite growing heterogeneity. In the following section we
describe the features that configure Mechanical Turk as a sophisticated
subject pool, and we address some potential concerns with its use such
as validity and generalizability.</P><!--TOC section Conducting experimental research on Mechanical Turk-->
<H2 CLASS="section"><!--SEC ANCHOR --><A NAME="htoc5">3</A>&#XA0;&#XA0;Conducting experimental research on Mechanical Turk</H2><!--SEC END --><BLOCKQUOTE CLASS="table"><DIV CLASS="center"><DIV CLASS="center"><HR WIDTH="80%" SIZE=2></DIV><DIV CLASS="caption"><TABLE CELLSPACING=6 CELLPADDING=0><TR><TD VALIGN=top ALIGN=left>Table 1: Tradeoffs of different recruiting methods.</TD></TR>
</TABLE></DIV>
<TABLE CELLSPACING=6 CELLPADDING=0><TR><TD VALIGN=middle ALIGN=left>&nbsp;</TD><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">Laboratory</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">Traditional web study</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">Web study with purpose built website</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">Mechanical Turk</DIV></TD></TR>
<TR><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">Susceptibility to coverage error</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">High</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">Moderate</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">Moderate</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">Low</DIV></TD></TR>
<TR><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">Heterogeneity of samples across labs</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">Moderate</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">High</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">High</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">Low</DIV></TD></TR>
<TR><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">Non-response error</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">Low</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">High</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">High</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">Moderate</DIV></TD></TR>
<TR><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">Subject Motivation</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">Moderate / High</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">Low</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">Low</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">Low</DIV></TD></TR>
<TR><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">Risk of multiple responses by one person</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">None</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">Moderate</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">Moderate</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">Low</DIV></TD></TR>
<TR><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">Risk of contaminated subject pool</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">Moderate</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">High</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">Moderate</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">Low</DIV></TD></TR>
<TR><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">Risk of dishonest responses</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">Moderate</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">Low</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">Low</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">Low</DIV></TD></TR>
<TR><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">Risk of experimenter effects</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">Low</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">None</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">None</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">None</DIV></TD></TR>
</TABLE>
<DIV CLASS="center"><HR WIDTH="80%" SIZE=2></DIV></DIV></BLOCKQUOTE><P>In this section we elaborate on how Mechanical Turk can serve as a
sophisticated subject pool for running online experimentation. We point
out some practical features that can make it easier to conduct certain
kinds of research, and argue about how Mechanical Turk solves some
typical concerns about Internet research.</P><!--TOC subsection Practical advantages of Mechanical Turk-->
<H3 CLASS="subsection"><!--SEC ANCHOR --><A NAME="htoc6">3.1</A>&#XA0;&#XA0;Practical advantages of Mechanical Turk</H3><!--SEC END --><P><I>Supportive infrastructure.</I> Researchers who use Mechanical
Turk benefit from the platform&#X2019;s services in various stages of the
research process. Although the speed of recruitment depends on the HIT
features (e.g. payment; Burhmester et al., in press), recruiting is
generally fast. (It took us three weeks to collect 1000 subjects.)
Moreover, because many workers accept to participate at the same time,
Mechanical Turk makes it potentially simpler to run experiments that
require interactions between subjects (e.g., game theory experimental
designs or group decision-making).</P><P>When designing a HIT, researchers can either use Mechanical Turk&#X2019;s
rudimentary in-house survey platform, or provide a link to an external
site for workers to follow. When using external sites it is important
to remember that eventually the experimenter will need to verify
workers&#X2019; claimed participation. One way to verify participation is to
assign each worker an identification code (or have workers generate
codes themselves) that can be used to match survey responses to
payment claims. Requesters are paid by Mechanical Turk, possibly
removing the burden of reporting individual payments (for tax
purposes) from the hands of the experimenter. Therefore, in general
the payment process is very smooth and accomplished with just a
one-click procedure.</P><P><I>Subject anonymity</I>. Workers are anonymous to the people who
can view their responses. If subjects complete a HIT using external
survey software, individual responses are not visible to requesters on
Mechanical Turk, thus ensuring that subjects&#X2019; responses cannot be
linked to their identity by any single individual. Thus, Institutional
Review Boards (IRBs, for research involving human subjects) are more likely
to treat studies in Mechanical Turk as exempt from reviews, and this
reduces concerns about how to safely store responses to sensitive
questions.</P><P><I>Subject identifiability and prescreening.</I> Mechanical Turk
workers can be required to earn &#X201C;qualifications&#X201D; prior to completing
a HIT. Qualifications are essentially prescreening questions that can
be used to constrain who can see and complete particular HITs. Thus
an experiment could be conducted on only women, or people who can
correctly answer sports trivia questions, or people who are anxious
about the economy, or whatever population the experimenter wishes to
use. Qualifications can also be used to measure potential moderator
variables, either by designing qualifications so that different
responses lead different HITs to become visible (thus creating
different groups that can then be compared) or by linking
qualification responses to survey responses using the worker ID. This
strategy allows a temporal separation between the collection of
moderator variables and the collection of other variables, thereby
reducing the likelihood that prescreening responses will contaminate
subsequent responses.</P><P><I>Subject identifiability and longitudinal studies. </I>Additionally,
identifiability allows experimenters to continue collecting data from
the same group of users over time. Worker IDs can be used to explicitly
recontact former subjects or code can be written that restricts the
availability of a HIT to a predetermined list of workers.</P><P><I>Cultural Diversity.</I> HITs can be confined to only workers who
live in specific countries, allowing for focused comparisons between
subjects from two or more groups (Eriksson &amp; Simpson, 2010). This can
eliminate many of the barriers to conducting cross-cultural comparisons
of basic psychological processes, namely, finding a subject pool in the
country of interest or a collaborator who can collect the data.
Furthermore, the content of each HIT posting can be uniquely tailored
to the residents of that country. </P><P>This can allow subjects to see the survey in their first language (if
desired), and decisions about money can be made using both the local
currency and values that reflect the average wages and standard of
living of that country. As Mechanical Turk is populated by an
increasingly internationalized workforce, we foresee large scope for
cross-culture comparisons in the future.</P><!--TOC subsection Potential threats to validity and generalizability.-->
<H3 CLASS="subsection"><!--SEC ANCHOR --><A NAME="htoc7">3.2</A>&#XA0;&#XA0;Potential threats to validity and generalizability.</H3><!--SEC END --><P>As an unfamiliar method of recruiting subjects, researchers may be
concerned about the validity and generalizability of results obtained
from Mechanical Turk. There are two primary concerns about Mechanical
Turk. First, there are concerns about whether Mechanical Turk workers
are representative of the desired population as a whole (whatever that
may be). Second, there were concerns about the overall quality of the
data that respondents provide. We briefly review the reason why these
issues are of concern and compare Mechanical Turk to other methods of
data collection on these dimensions. Table 1 provides a comparative
summary.</P><!--TOC subsubsection Representativeness of samples-->
<H4 CLASS="subsubsection"><!--SEC ANCHOR --><A NAME="htoc8">3.2.1</A>&#XA0;&#XA0;Representativeness of samples</H4><!--SEC END --><P>Concerns about the representativeness of a sample include concerns
about whether the people recruited and who choose to participate match
the population of interest. Our demographic data suggests that
Mechanical Turk workers are at least as representative of the U.S.
population as traditional subject pools, with gender, race, age and
education of Internet samples all matching the population more closely
than college undergraduate samples and internet samples in general
(see also Buhrmester et al., in press). More importantly, as we
demonstrate in Section 4, non-response error seems to be less of a
concern in Mechanical Turk samples than in Internet convenience
samples recruited through other means.</P><!--TOC subsubsection Data quality-->
<H4 CLASS="subsubsection"><!--SEC ANCHOR --><A NAME="htoc9">3.2.2</A>&#XA0;&#XA0;Data quality</H4><!--SEC END --><P>Given that Mechanical Turk workers are paid so little, one may wonder
whether they take experiments seriously. Another concern is that the
anonymity of the Internet may lead individual subjects to provide many
separate responses to the same study. There is little evidence to
suggest that data collected online is necessarily of poorer quality
than data collected from subject pools (Krantz &amp; Dalal, 2000; Gosling
et al., 2004). Further, in practice, multiple responses are rare in
web based experiments and are even less of a problem for Mechanical
Turk because each worker ID must correspond to a unique credit card
number (for a detailed discussion, see Horton et al., 2010).</P><P>One potential drawback of Mechanical Turk experiments (that actually
applies to all web based experiments) is that unsupervised subjects
tend to be less attentive than subjects in a lab with an experimenter
(Oppenheimer et al., 2009). However, this problem is solvable; either
through &#X201C;catch trials&#X201D; that identify subjects who failed to pay
close attention, or through instructional manipulation checks that
identify inattentive subjects and remind them to pay more attention
(Oppenheimer et al., 2009).</P><!--TOC subsubsection Mechanical Turk can strengthen internal validity-->
<H4 CLASS="subsubsection"><!--SEC ANCHOR --><A NAME="htoc10">3.2.3</A>&#XA0;&#XA0;Mechanical Turk can strengthen internal validity</H4><!--SEC END --><P>Mechanical Turk workers can complete experiments without interacting
with experimenters, possibly without even knowing that they are in an
experiment. This avoids concerns of experimenter bias (Orne, 1962),
subject crosstalk (Edlund et al., 2009) and reactance (for a
detailed discussion of the validity of experiments conducted using
online labor markets see Horton et al., 2010).</P><!--TOC section A comparative study-->
<H2 CLASS="section"><!--SEC ANCHOR --><A NAME="htoc11">4</A>&#XA0;&#XA0;A comparative study</H2><!--SEC END --><P>We have conducted numerous replications of traditional JDM findings on
Mechanical Turk, suggesting that it is reliable (see
http://experimentalturk.wordpress.com). We extend these
findings by directly comparing Mechanical Turk data with data
collected from other sources.</P><P>We recruited subjects from three different sources: Mechanical Turk, a
traditional subject pool at a large Midwestern U.S. university, and
visitors of online discussion boards. The study (carried out in April
and May 2010) provides additional evidence on the consistency between
Mechanical Turk workers and more traditional subjects, with respect to
both actual behavior and attention provided to the experimental tasks.</P><BLOCKQUOTE CLASS="table"><DIV CLASS="center"><DIV CLASS="center"><HR WIDTH="80%" SIZE=2></DIV>
<DIV CLASS="caption"><TABLE CELLSPACING=6 CELLPADDING=0><TR><TD VALIGN=top ALIGN=left>Table 2: Subject pools characteristics.</TD></TR>
</TABLE></DIV>
<TABLE CELLSPACING=6 CELLPADDING=0><TR><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">Subject pool</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">% Females</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">Average age</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">Median age</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">Subjective
numeracy (SD)</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">% Failed catch trials</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">% Survey completion</DIV></TD></TR>
<TR><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">Mechanical Turk</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">75.0%</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">34.3</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">29</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">4.35 (1.00)</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">4.17%</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">91.6%</DIV></TD></TR>
<TR><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">Midwestern university</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">68.8%</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">18.8</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">19</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">4.17 (0.81)</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">6.47%</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">98.6%</DIV></TD></TR>
<TR><TD VALIGN=middle ALIGN=left><DIV CLASS="flushleft">Internet boards</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">52.6%</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">30.6</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">26</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">4.25 (1.16)</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">5.26%</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">69.3%</DIV></TD></TR>
</TABLE>
<DIV CLASS="center"><HR WIDTH="80%" SIZE=2></DIV></DIV></BLOCKQUOTE><!--TOC subsection The survey-->
<H3 CLASS="subsection"><!--SEC ANCHOR --><A NAME="htoc12">4.1</A>&#XA0;&#XA0;The survey</H3><!--SEC END --><P>Subjects completed three classic experimental tasks drawn from the
heuristics and biases literature. The survey was completed using
Qualtrics survey software. Questionnaires were identical across
conditions with the exception that Mechanical Turk workers were asked
to provide a code automatically generated by Qualtrics at the end of
the experiment.</P><P>The <I>Asian disease problem</I> (Tversky &amp; Kahneman, 1981)
demonstrates framing effects. Subjects had to choose what action plan
between a riskier and a safer one they preferred in order to contrast
the outbreak of an unusual disease. In a between-subjects manipulation,
the outcomes of the plans were either framed in positive terms (people
saved), or in negative terms (people lost). </P><P>The <I>Linda problem</I> (Tversky &amp; Kahneman, 1983) demonstrates the
conjunction fallacy, that is the fact that people often fail to regard
a combination of events as less probable than a single event in the
combination. Respondents read a description of Linda and rated which of
two alternative profiles was more likely to describe Linda, with one
being more general than the other. </P><P>The <I>physician problem</I> (Baron &amp; Hershey, 1988; Experiment 1,
Cases 1 and 2) demonstrates the outcome bias, the fact that stated
judgments of quality of a decision often depend on the valence of the
outcome. Subjects rated on a seven-point scale (as used by Stanovich
&amp; West, 2008) the quality of a physician&#X2019;s decision to perform an
operation on a patient. The operation was described as either a
success or a failure in a between-subjects design.</P><P>After completing these three tasks, subjects completed the Subjective
Numeracy Scale (SNS; Fagerlin et al. 2007). The SNS is an eight-item
self-report measure of perceived ability to perform various
mathematical tasks and preference for the use of numerical versus prose
information. Because of its high correlation with the numeracy measure
(Lipkus et al., 2001), the SNS provides a parsimonious measurement of
an individual&#X2019;s quantitative abilities. Therefore,
evidence of low quantitative score on the SNS may raise some concerns
regarding the actual capacity of workers in Mechanical Turk to
appreciate the magnitude of the wages/effort ratio in listed HITs.</P><P>Moreover, the SNS provided an ideal context for a catch trial that
measured whether subjects were attending to the
questions. Included with the SNS, subjects read a question that
required them to give a precise and obvious answer (&#X201C;<I>While
watching the television, have you ever had a fatal heart
attack?</I>&#X201D;). This question employed a six-point scale anchored on
&#X201C;<I>Never</I>&#X201D; and &#X201C;<I>Often</I>&#X201D; very similar to those in the
SNS, thus representing an ideal test of whether subjects paid
attention to the survey or not.</P><!--TOC subsection The samples-->
<H3 CLASS="subsection"><!--SEC ANCHOR --><A NAME="htoc13">4.2</A>&#XA0;&#XA0;The samples</H3><!--SEC END --><P><I>Amazon Mechanical Turk. </I>We posted a task that required
workers to complete an externally hosted survey in exchange for
$0.10. The HIT was titled &#X201C;Answer a short decision survey&#X201D; and
described as &#X201C;Make some choices and judgments in this 5-minutes
survey&#X201D;. The (overestimated) completion time was included in the HIT
description in order to provide workers with a rough assessment of the
reward/effort ratio. The actual ratio was $1.71/hour. The HIT was
visible only to workers with an acceptance rate greater than 95% and
who were residents in the U.S. One hundred thirty-one workers took
part in the study.</P><P><I>Lab subject pool</I>. One hundred and forty-one students from an
introductory subject pool at a large Midwestern U.S. university
completed this study.</P><P><I>Internet Discussion Boards</I>. We posted a link to the survey to
several online discussion boards that host online experiments in
psychology. The survey has been available online for two weeks, and one
hundred thirty-seven visitors took part in the study.</P><!--TOC subsection Results-->
<H3 CLASS="subsection"><!--SEC ANCHOR --><A NAME="htoc14">4.3</A>&#XA0;&#XA0;Results</H3><!--SEC END --><P><I>Subjects&#X2019; demographics.</I> Subjects (<I>N</I> = 318, 66.0%
female, M<SUB>age</SUB> = 28.3) were recruited from Mechanical
Turk, discussion boards around the Internet and an introductory
subject pool at a Midwestern U.S. University. Subjects recruited from
the Internet boards were comparable in terms of average age to
subjects recruited from Mechanical Turk (34.3 and 31.8 respectively)
and unsurprisingly, both were older than subjects recruited from the
lab subject pool (18.8). Table 2 summarizes the demographics.</P><BLOCKQUOTE CLASS="table"><DIV CLASS="center"><DIV CLASS="center"><HR WIDTH="80%" SIZE=2></DIV><DIV CLASS="caption"><TABLE CELLSPACING=6 CELLPADDING=0><TR><TD VALIGN=top ALIGN=left>Table 3: Results on experimental tasks.</TD></TR>
</TABLE></DIV>
<TABLE CELLSPACING=6 CELLPADDING=0><TR><TD VALIGN=middle ALIGN=left>&nbsp;</TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">Mechanical Turk</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">Midwestern university</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">Internet boards</DIV></TD></TR>
<TR><TD VALIGN=middle ALIGN=left><I>Asian Disease</I></TD><TD VALIGN=middle ALIGN=left>&nbsp;</TD><TD VALIGN=middle ALIGN=left>&nbsp;</TD><TD VALIGN=middle ALIGN=left>&nbsp;</TD></TR>
<TR><TD VALIGN=middle ALIGN=left>% Risky Positive Frame</TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">17.6%</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">28.1%</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">23.7%</DIV></TD></TR>
<TR><TD VALIGN=middle ALIGN=left>% Risky Negative Frame</TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">55.3%</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">67.7%</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">63.0%</DIV></TD></TR>
<TR><TD VALIGN=middle ALIGN=left>&#X3C7; <SUP>2</SUP></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">10.833</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">20.230</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">13.013</DIV></TD></TR>
<TR><TD VALIGN=middle ALIGN=left>p</TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">&lt; 0.001</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">&lt; 0.001</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">&lt; 0.001</DIV></TD></TR>
<TR><TD VALIGN=middle ALIGN=left>Effect size (w)</TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">0.39</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">0.39</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">0.39</DIV></TD></TR>
<TR><TD VALIGN=middle ALIGN=left><I>Linda problem</I></TD></TR>
<TR><TD VALIGN=middle ALIGN=left>% Conjunction Fallacy</TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">72.2%</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">78.3%</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">64.4%</DIV></TD></TR>
<TR><TD VALIGN=middle ALIGN=left><I>Physician problem</I></TD></TR>
<TR><TD VALIGN=middle ALIGN=left>Avg. Quality Success (SD)</TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">5.93 (0.81)</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">5.63 (0.75)</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">5.73 (0.98)</DIV></TD></TR>
<TR><TD VALIGN=middle ALIGN=left>Avg. Quality Failure (SD)</TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">5.13 (1.24)</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">4.86 (1.29)</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">4.93 (1.41)</DIV></TD></TR>
<TR><TD VALIGN=middle ALIGN=left>t</TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">3.70</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">4.14</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">2.547</DIV></TD></TR>
<TR><TD VALIGN=middle ALIGN=left>p</TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">&lt; 0.001</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">&lt; 0.001</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">0.007</DIV></TD></TR>
<TR><TD VALIGN=middle ALIGN=left>Effect size (d)</TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">0.76</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">0.73</DIV></TD><TD VALIGN=middle ALIGN=left><DIV CLASS="center">0.66</DIV></TD></TR>
</TABLE>
<DIV CLASS="center"><HR WIDTH="80%" SIZE=2></DIV></DIV></BLOCKQUOTE><P><I>Non-response error. </I>We looked at the number of people who
accessed to the study but did not complete it entirely. As expected,
almost everybody in the lab subject pool completed the study (98.6%).
Subjects recruited from online discussion forums were significantly
less likely to complete the survey than subjects on Mechanical Turk
(66.7% and 91.6% respectively), &#X3C7; <SUP>2</SUP>(1,268) =
20.915, p &lt; .001. This suggests that Mechanical Turk strongly
diminishes the potential for non-response error in online research.</P><P><I>Attention. </I>Subjects in the three subject pools did not differ
in terms of attention provided to the survey. Subjects in Mechanical
Turk had the lowest catch trial failing rate (defined as the
proportion of subjects who did not select &#X201C;<I>Never</I>&#X201D; to the
question &#X201C;<I>While watching the television, have you ever had a
fatal heart attack?&#X201D;</I>), although the number of respondents who
failed the catch trial is very low and not significantly different
across subject pools, &#X3C7; <SUP>2</SUP>(2,301) = .187,
<I>p</I> = 0.91. Subjects who failed the catch trial, or did not
reach the page containing the catch trial, were removed from
subsequent analyses.</P><P><I>Subjective numeracy</I>. Subjects in the three subject pools
did not differ significantly in the SNS score, <I>F</I>(2,299) =
1.193, <I>p </I>= 0.30. As the SNS is closely associated with many
measures of quantitative ability, this result suggests that workers in
Mechanical Turk are not less able to handle quantitative information
(e.g. payments for participation) than more traditional experimental
subjects.</P><P><I>Experimental tasks. </I>Table 3 summarizes the results obtained in
the experimental tasks. The present tasks, along with their variations,
are widely used in judgment and decision-making, and in particular they
had already been posted repeatedly on Mechanical Turk
(http://experimentalturk.wordpress.com; Horton
et al., 2010). Therefore, for each task we excluded from the analysis
subjects who declared they previously completed the task.</P><P>In the Asian disease problem, people were significantly more likely to
choose the risky course of action when the problem was framed in terms
of losses than when it was framed in terms of gains. Effect sizes are
exactly the same across samples. Note that subjects on Mechanical Turk
exhibited more risk aversion than subjects in the other subject pools,
although this did not occur in previous tests of the same problem
(http://experimentalturk.wordpress.com; Horton et al., 2010).</P><P>Respondents in all subject pools exhibited the conjunction fallacy.
Large majorities regarded a combination of events (&#X201C;Linda is a bank
teller and is active in the feminist movement&#X201D;) as more probable than
a single event in the combination (Linda is a bank teller&#X201D;). We
found slight differences across samples for this effect, &#X3C7;
<SUP>2</SUP>(2,274 = 4.606, <I>p </I>= 0.1, however this is
consistent with the large variability of results in the conjunction
fallacy literature (e.g., Charness, Karni, &amp; Levin 2009).</P><P>Subjects in all the subject pools showed an outcome bias. In the
physician problem, subjects judged the quality of the physician
decision to be higher when it was followed by a success than when it
was followed by a failure. The result is significant in all the subject
pools, and the effect size in Mechanical Turk is the highest among the
three samples.</P><P>Overall, these results confirm that Mechanical Turk is a reliable source
of experimental data in judgment and decision-making. Results obtained
in Mechanical Turk did not substantially differ from results obtained
in a subject pool at a large Midwestern U.S. university. Moreover,
response error was significantly lower in Mechanical Turk than in
Internet discussion boards.</P><!--TOC section Concluding comments-->
<H2 CLASS="section"><!--SEC ANCHOR --><A NAME="htoc15">5</A>&#XA0;&#XA0;Concluding comments</H2><!--SEC END --><P>Our theoretical discussion and empirical findings suggest that
experimenters should consider Mechanical Turk as a viable alternative
for data collection. Workers in Mechanical Turk exhibit the classic
heuristics and biases and pay attention to directions at least as much
as subjects from traditional sources. Furthermore, Mechanical Turk
offers many practical advantages that reduce costs and make recruitment
easier, while also reducing threats to internal validity. However,
unlike traditional subject pools, which are reset every year when a new
class arrives, Mechanical Turk membership evolves more organically and
some workers may be potential experimental subjects for years. This
means that experimenters will need to be more careful about how they
manage relationships with subjects. We conclude the article
highlighting two open issues that should be considered by experimenters
in light of this difference. </P><P><I>Tracking subjects to ensure independent responses across
experiments.</I> Thanks to the workers&#X2019; unique ID,
researchers can identify workers who already took part to previous
versions of an experiment, and exclude them accordingly. The easiest
way to do this is to post a single HIT that redirects to a splash page.
The url that the splash page directs workers to can be changed and all
subjects will be unique. Researchers who have basic web programming
skills can also specify workers that should not see the HIT, making it
possible to post many HITs while avoiding subject pool contamination
(for details on how to do this, see the most recent developer guide
here:
http:&#XA0;//&#XA0;developer.amazonwebservices.com/connect/kbcategory. jspa?categoryID=28)</P><P>However, there is no way to know whether a certain subject already took
a similar version of the experiment posted by some other researcher.
Given that many experiments are designed as slight variations of
paradigmatic ones (e.g., Asian disease) it is probably also wise to ask
subjects whether they already completed previous versions of the tasks.</P><P><I>Maintaining a positive reputation among workers. </I>Experimenters
should keep in mind that, although there is no direct way for workers to
retaliate against poor employers, workers can refuse to complete tasks
because the payment is clearly not adequate or because they previously
had a bad experience with a requester. Because workers can share these
bad experiences on blogs and other outlets (e.g.,
http://turkopticon.differenceengines.com),
careless researchers can create problems for themselves (or others
associated with them) if their HIT descriptions are confusing or
misrepresent the time and effort required.</P><P>In principle requesters can offer workers wages that are
disproportionately low, even considering what the norms are on
Mechanical Turk, with little concern since data quality seems to be not
affected by payments (Mason &amp; Watts, 2009). Workers are capable of
sorting HITs by payment and reading the description before they choose
to accept. However, researchers should be transparent about the wage
they set and ensure that the time and the effort required to complete
the task is provided in the HIT description. Not only is will this
ensure that workers are able to make an informed decision about whether
or not to complete a HIT, it will also reduce attrition (Crawford et
al., 2001) and avoid potential reputational damage to the researcher. </P><P>A somewhat more complicated issue is deciding whether or not a HIT
should be rejected. Here, the experimenter must balance community
norms of Mechanical Turk, which require &#X201C;bad&#X201D; responses to be
rejected, with the inherently subjective nature of experimental
responses and IRB requirements to avoid penalizing subjects who
withdraw from experiments. One possible solution is to include a
non-subjective, non-experimental task before the survey that can be
used to verify worker effort. Another solution is to require that
subjects specifically click a link to opt out of the survey. In
most cases, it may be best to give the workers the benefit of the
doubt and pay them, but block them from participating in future
experiments. When rejecting a HIT, it is always a good idea to provide
concrete and justifiable reasons in writing to prevent
misunderstandings.</P><!--TOC section References-->
<H2 CLASS="section"><!--SEC ANCHOR -->References</H2><!--SEC END --><DIV CLASS="hangparas1"><P>Alter, A. L., Oppenheimer, D. M., &amp; Zemla, J. C. (in press). Missing the
trees for the forest: A construal level account of the illusion of
explanatory depth. <I>Journal of Personality and Social
Psychology</I>.</P><P>Baron, J., &amp; Hershey, J. C. (1988). Outcome bias in decision
evaluation. <I>Journal of Personality and Social Psychology,
54</I>, 569&#X2013;579.</P><P>Buhrmester, M. D., Kwang, T., Gosling, S. D. (in press). Amazon&#X2019;s
Mechanical Turk: A new source of inexpensive, yet high-quality, data?.
<I>Perspectives on Psychological Science</I>.</P><P>Chandler, D. &amp; Kapelner, A. (2010). Breaking monotony with meaning:
Motivation in crowdsourcing markets. <I>University of Chicago
mimeo</I>.</P><P>Charness, G., Karni, E., &amp; Levin, D. (2009). On the conjunction
fallacy in probability judgment: New experimental evidence regarding
Linda. <I>Games and Economic Behavior</I>, <I>68</I>,
551&#X2013;556</P><P>Crawford, S., Couper, M. P., Lamias, M. (2001). Web Surveys: Perceptions
of Burden. <I>Social Science Computer Review, 19</I>, 146&#X2013;162.</P><P>Edlund, J. E., Sagarin, B. J., Skowronski, J. J., Johnson, S. J.,
Kutter, J. (2009). Whatever happens in the laboratory stays in the
laboratory: The prevalence and prevention of participant
crosstalk.<I>Personality and Social Psychology Bulletin</I>,
<I>35</I>, 635&#X2013;642.</P><P>Eriksson, K., &amp; Simpson, B. (2010). Emotional reactions to losing
explain gender differences in entering a risky
lottery. <I>Judgment and Decision Making</I>, <I>5</I>, 159&#X2013;163.</P><P>Fagerlin, A., Zikmund-Fisher, B., Ubel, P., Jankovic, A., Derry, H.,
&amp; Smith, D. (2007). Measuring numeracy without a math test:
Development of the subjective numeracy scale. <I>Medical Decision
Making</I>, <I>27</I>, 672&#X2013;680.</P><P>Gosling, S., Vazire, S., Srivastava, S., &amp; John, O. (2004). Should We
trust web-based studies? A comparative analysis of six preconceptions
about internet questionnaires. <I>American Psychologist</I>,
<I>59</I>, 93&#X2013;104.</P><P>Horton, J., &amp; Chilton, L. (in press). The labor economics of paid
crowdsourcing. <I>Proceedings of the 11th ACM Conference on
Electronic Commerce</I>.</P><P>Horton, J., Rand, D., &amp; Zeckhauser, R. (2010). The online laboratory:
Conducting experiments in a real labor market. <I>NBER Working
Paper</I> w15691.</P><P>Ipeirotis, P. (2009). Turker demographics vs. Internet demographics.
http://behind-the-enemy-lines.blogspot.com/2009/03/turker-demographics-vs-internet.html.
Accessed August 18, 2010.</P><P>Ipeirotis, P. (2010). Demographics of Mechanical Turk.
<I>CeDER-10&#X2013;01 working paper</I>, New York University.</P><P>Krantz, J. H., &amp; Dalal, R. (2000). Validity of web-based
psychological research. In M. H. Birnbaum (Ed.), <I>Psychological
experiments on the Internet</I> (pp. 35&#X2013;60). New York: Academic
Press.</P><P>Lipkus, I., Samsa, G., &amp; Rimer, B. (2001). General performance on a
numeracy scale among highly educated samples. <I>Medical Decision
Making</I>, <I>21</I>, 37&#X2013;44.</P><P>Mason, W., &amp; Watts, D. (2009). Financial incentives and the
&#X201C;performance of crowds.&#X201D; <I>HCOMP &#X2019;09: Proceedings of the ACM
SIGKDD Workshop on Human Computation, </I>77&#X2013;85<I>.</I></P><P>Oppenheimer, D. M., Meyvis, T., &amp; Davidenko, N.
(2009). Instructional manipulation checks: Detecting satisficing to
increase statistical power. <I>Journal of Experimental Social
Psychology, 45</I>, 867&#X2013;872.</P><P>Orne, M. T. (1962). On the social psychology of the psychological
experiment: With particular reference to demand characteristics and
their implications. <I>American Psychologist</I>,
<I>17</I>, 776&#X2013;783.</P><P>Rosenthal, R., &amp; Rubin, D. B. (1979). Interpersonal expectancy
effects: The first 345 studies. <I>The Behavioral and Brain
Sciences</I>, <I>1</I>, 377&#X2013;415.</P><P>Ross, J., Irani, L., Silberman, M. S., Zaldivar, A., &amp; Tomlinson, B.
(2010). Who are the crowdworkers?: shifting demographics in mechanical
turk. In <I>CHI EA &#X2019;10: Proceedings of the 28th of the
international conference extended abstracts on Human factors in
computing systems</I>, pp. 2863&#X2013;2872, New York, NY, USA. ACM.</P><P>Stanovich, K. E., &amp; West. R. F. (2008). On the relative independence of
thinking biases and cognitive ability. <I>Journal of Personality
and Social Psychology</I>, <I>94</I>, 672&#X2013;695.</P><P>Tversky, A., &amp; Kahneman, D. (1981). The framing of decisions and the
psychology of choice. <I>Science</I>, <I>211</I>,
453&#X2013;458.</P></DIV><DIV CLASS="hangparas2"><P>Tversky, A., &amp; Kahneman, D. (1983). Extensional versus intuitive
reasoning: The conjunction fallacy in probability judgment.
<I>Psychological Review</I>, <I>90</I>, 293&#X2013;315.</P><P>U.S. Census Bureau (2007). Current Population Survey, 2007 Annual
Social and Economic Supplement, Table HINC-06.
http://pubdb3.census.gov/macro/032007/hhinc/new06 _000.htm. Accessed
August 19, 2010.</P></DIV><!--BEGIN NOTES document-->
<HR CLASS="footnoterule"><DL CLASS="thefootnotes"><DT CLASS="dt-thefootnotes">
<A NAME="note1" HREF="#text1">*</A></DT><DD CLASS="dd-thefootnotes"><DIV CLASS="footnotetext">The authors thank Massimo Warglien
and contributors to the Experimental Turk blog for useful
discussions, and the editor Jonathan Baron for helpful
suggestions. Gabriele Paolacci receives financial support by
Fondazione Coin. Panagiotis G. Ipeirotis is supported by the
National Science Foundation under Grant No. IIS-0643846 and by a
New York University Research Challenge Fund. Address: Gabriele
Paolacci, Advanced School of Economics, Ca&#X2019; Foscari University,
Cannaregio 873, 30121 Venice,
Italy. Email: paolacci@unive.it.</DIV>
</DD></DL>
<!--END NOTES-->
<!--CUT END -->
<!--HTMLFOOT-->
<!--ENDHTML-->
<!--FOOTER-->
<HR SIZE=2><BLOCKQUOTE CLASS="quote"><EM>This document was translated from L<sup>A</sup>T<sub>E</sub>X by
<A HREF="http://hevea.inria.fr/index.html">H<FONT SIZE=2><sup>E</sup></FONT>V<FONT SIZE=2><sup>E</sup></FONT>A</A>.</EM></BLOCKQUOTE></BODY>
</HTML>
