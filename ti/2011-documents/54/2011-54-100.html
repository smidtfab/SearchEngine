<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en" dir="ltr">
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
		<meta http-equiv="Content-Style-Type" content="text/css" />
		<meta name="generator" content="MediaWiki 1.14.0" />
		<meta name="keywords" content="Events" />
		<link rel="shortcut icon" href="/favicon.ico" />
		<link rel="search" type="application/opensearchdescription+xml" href="/clip/opensearch_desc.php" title="Clip (en)" />
		<link rel="alternate" type="application/rss+xml" title="Clip RSS Feed" href="https://wiki.umiacs.umd.edu/clip/index.php?title=Special:RecentChanges&amp;feed=rss" />
		<link rel="alternate" type="application/atom+xml" title="Clip Atom Feed" href="https://wiki.umiacs.umd.edu/clip/index.php?title=Special:RecentChanges&amp;feed=atom" />
		<title>Events - Clip</title>
		<link rel="stylesheet" href="/clip/skins/common/shared.css?195" type="text/css" media="screen" />
		<link rel="stylesheet" href="/clip/skins/common/commonPrint.css?195" type="text/css" media="print" />
		<link rel="stylesheet" href="/clip/skins/gumax/gumax_main.css?195" type="text/css" media="screen" />
		<!--[if lt IE 5.5000]><link rel="stylesheet" href="/clip/skins/gumax/IE50Fixes.css?195" type="text/css" media="screen" /><![endif]-->
		<!--[if IE 5.5000]><link rel="stylesheet" href="/clip/skins/gumax/IE55Fixes.css?195" type="text/css" media="screen" /><![endif]-->
		<!--[if IE 6]><link rel="stylesheet" href="/clip/skins/gumax/IE60Fixes.css?195" type="text/css" media="screen" /><![endif]-->
		<!--[if IE 7]><link rel="stylesheet" href="/clip/skins/gumax/IE70Fixes.css?195" type="text/css" media="screen" /><![endif]-->
		<link rel="stylesheet" href="/clip/skins/gumax/gumax_print.css?195" type="text/css" media="print" />
		<link rel="stylesheet" href="/clip/index.php?title=MediaWiki:Common.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=18000&amp;action=raw&amp;maxage=18000" type="text/css" />
		<link rel="stylesheet" href="/clip/index.php?title=MediaWiki:Print.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=18000&amp;action=raw&amp;maxage=18000" type="text/css" media="print" />
		<link rel="stylesheet" href="/clip/index.php?title=MediaWiki:Gumax.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=18000&amp;action=raw&amp;maxage=18000" type="text/css" />
		<link rel="stylesheet" href="/clip/index.php?title=-&amp;action=raw&amp;maxage=18000&amp;gen=css" type="text/css" />
		<!--[if lt IE 7]><script type="text/javascript" src="/clip/skins/common/IEFixes.js?195"></script>
		<meta http-equiv="imagetoolbar" content="no" /><![endif]-->

		<script type= "text/javascript">/*<![CDATA[*/
		var skin = "gumax";
		var stylepath = "/clip/skins";
		var wgArticlePath = "/clip/index.php/$1";
		var wgScriptPath = "/clip";
		var wgScript = "/clip/index.php";
		var wgVariantArticlePath = false;
		var wgActionPaths = {};
		var wgServer = "https://wiki.umiacs.umd.edu";
		var wgCanonicalNamespace = "";
		var wgCanonicalSpecialPageName = false;
		var wgNamespaceNumber = 0;
		var wgPageName = "Events";
		var wgTitle = "Events";
		var wgAction = "view";
		var wgArticleId = "6";
		var wgIsArticle = true;
		var wgUserName = null;
		var wgUserGroups = null;
		var wgUserLanguage = "en";
		var wgContentLanguage = "en";
		var wgBreakFrames = false;
		var wgCurRevisionId = "355";
		var wgVersion = "1.14.0";
		var wgEnableAPI = true;
		var wgEnableWriteAPI = true;
		var wgSeparatorTransformTable = ["", ""];
		var wgDigitTransformTable = ["", ""];
		var wgRestrictionEdit = [];
		var wgRestrictionMove = [];
		/*]]>*/</script>

		<script type="text/javascript" src="/clip/skins/common/wikibits.js?195"><!-- wikibits js --></script>
		<!-- Head Scripts -->
		<script type="text/javascript" src="/clip/skins/common/ajax.js?195"></script>
		<script type="text/javascript" src="/clip/index.php?title=-&amp;action=raw&amp;gen=js&amp;useskin=gumax"><!-- site js --></script>


		<!-- gumax customized style -->

					<style type="text/css">
				#gumax-content-actions li#ca-talk,
				#gumax-content-actions li#ca-history,
				#gumax-content-actions li#ca-edit,
				#gumax-personal-tools
				{ display: none; }
			</style>
		
		<!--[if lt IE 7]>
			<script type="text/javascript" src="/clip/skins/gumax/js/ieunitpngfix-tag.js"></script>
		<![endif]-->

		<!-- end of gumax customized style -->
</head>


<body class="mediawiki ltr ns-0 ns-subject page-Events skin-gumax">

<!-- ##### gumax-wrapper ##### -->
<div id="gumax-wrapper">

<table border="0" id="gumax-page-table"><tr><td id="gumax-page-table-left"><img src="/clip/skins/gumax/blank.gif" alt="" /></td><td width="100%" valign="top" style="padding: 0; margin: 0">


<!-- ===== gumax-page ===== -->
<div class="gumax-page">

	<!-- ///// gumax-header ///// -->
	<div id="gumax-header">
		<a name="top" id="contentTop"></a>

		<!-- gumax-p-logo -->
	<div id="gumax-p-logo">
		<div id="p-logo">
			<a style="background-image: url(/clip/skins/gumax/images/pages/page-Main_Page.JPG);" href="/clip/index.php/Main_Page" title="Main Page"></a>
		</div>
	</div>
	<script type="text/javascript"> if (window.isMSIE55) fixalpha(); </script>
	<!-- end of gumax-p-logo -->

		<!-- Login -->
	<div id="gumax-p-login">
		<ul>
				<li id="pt-login"><a href="/clip/index.php?title=Special:UserLogin&amp;returnto=Events" title="You are encouraged to log in; however, it is not mandatory [o]" accesskey="o">Log in</a></li>
		</ul>
	</div>
	<!-- end of Login -->

		<!-- Search -->
	<div id="gumax-p-search" class="gumax-portlet">
		<h5><label for="searchInput">Search</label></h5>
		<div id="gumax-searchBody" class="gumax-pBody">
			<form action="/clip/index.php/Special:Search" id="searchform"><div>
				<input id="searchInput" name="search" type="text" accesskey="f" value="" />
				<input type='submit' name="go" class="searchButton" id="searchGoButton" value="Go" title="Go to a page with this exact name if exists" />
				<input type='submit' name="fulltext" class="searchButton" id="mw-searchButton" value="Search" title="Search the pages for this text" />
			</div></form>
		</div>
	</div>
	<!-- end of Search -->

	</div>
	<!-- ///// end of gumax-header ///// -->


		<!-- Navigation Menu -->
	<div id="gumax-p-navigation">
			<div class="gumax-portlet gumax-p-navigation">
				<h5>Navigation</h5>
						<ul>
								<li id="n-mainpage-description"><a href="/clip/index.php/Main_Page">Main Page</a></li>
								<li id="n-People"><a href="/clip/index.php/People">People</a></li>
								<li id="n-Research"><a href="/clip/index.php/Research">Research</a></li>
								<li id="n-Teaching"><a href="/clip/index.php/Teaching">Teaching</a></li>
								<li id="n-Publications"><a href="http://clipsrv01.umiacs.umd.edu/wiki_pubs/ClipMedia.php">Publications</a></li>
								<li id="n-Events"><a href="/clip/index.php/Events">Events</a></li>
						</ul>
			</div>
			<div class="gumax-portlet gumax-p-navigation">
				<h5>SEARCH</h5>
			</div>
			<div class="gumax-portlet gumax-p-navigation">
				<h5>TOOLBOX</h5>
			</div>
			<div class="gumax-portlet gumax-p-navigation">
				<h5>LANGUAGES</h5>
			</div>
	</div>
	<!-- end of Navigation Menu -->
	<div class="gumax-p-navigation-spacer"></div>


	

		<!-- gumax-content-body -->
		<div id="gumax-column-content">
	<div id="content">
		<a name="top" id="top"></a>
				<h1 id="firstHeading" class="firstHeading gumax-firstHeading" >Events</h1>
		<div id="bodyContent" class="gumax-bodyContent">
			<h3 id="siteSub">From Clip</h3>
			<div id="contentSub"></div>
									<div id="jump-to-nav">Jump to: <a href="#column-one">navigation</a>, <a href="#searchInput">search</a></div>			<!-- start content -->
			<table id="toc" class="toc" summary="Contents"><tr><td><div id="toctitle"><h2>Contents</h2></div>
<ul>
<li class="toclevel-1"><a href="#Colloquia"><span class="tocnumber">1</span> <span class="toctext">Colloquia</span></a>
<ul>
<li class="toclevel-2"><a href="#Google_Calendar_for_CLIP_Speakers"><span class="tocnumber">1.1</span> <span class="toctext">Google Calendar for CLIP Speakers</span></a></li>
</ul>
</li>
<li class="toclevel-1"><a href="#Spring_2011_Speakers"><span class="tocnumber">2</span> <span class="toctext">Spring 2011 Speakers</span></a>
<ul>
<li class="toclevel-2"><a href="#April_6.2C_Sinead_Williamson:_Nonparametric_Bayesian_models_for_dependent_data"><span class="tocnumber">2.1</span> <span class="toctext">April 6, Sinead Williamson: Nonparametric Bayesian models for dependent data</span></a></li>
<li class="toclevel-2"><a href="#March_30.2C_Sujith_Ravi:_Deciphering_Natural_Language"><span class="tocnumber">2.2</span> <span class="toctext">March 30, Sujith Ravi: Deciphering Natural Language</span></a></li>
<li class="toclevel-2"><a href="#March_16.2C_Mark_Liberman:_Problems_and_opportunities_in_corpus_phonetics"><span class="tocnumber">2.3</span> <span class="toctext">March 16, Mark Liberman: Problems and opportunities in corpus phonetics</span></a></li>
<li class="toclevel-2"><a href="#March_9.2C_Asad_Sayeed:_Finding_Target-Relevant_Sentiment_Words"><span class="tocnumber">2.4</span> <span class="toctext">March 9, Asad Sayeed: Finding Target-Relevant Sentiment Words</span></a></li>
<li class="toclevel-2"><a href="#March_2.2C_Ned_Talley:_An_Unsupervised_View_of_NIH_Grants_-_Latent_Categories_and_Clusters_in_an_Interactive_Format"><span class="tocnumber">2.5</span> <span class="toctext">March 2, Ned Talley: An Unsupervised View of NIH Grants - Latent Categories and Clusters in an Interactive Format</span></a></li>
<li class="toclevel-2"><a href="#February_16.2C_Ophir_Frieder:_Humane_Computing"><span class="tocnumber">2.6</span> <span class="toctext">February 16, Ophir Frieder: Humane Computing</span></a></li>
<li class="toclevel-2"><a href="#February_9.2C_Naomi_Feldman:_Using_a_developing_lexicon_to_constrain_phonetic_category_acquisition"><span class="tocnumber">2.7</span> <span class="toctext">February 9, Naomi Feldman: Using a developing lexicon to constrain phonetic category acquisition</span></a></li>
<li class="toclevel-2"><a href="#February_2.2C_Ahn_Jae-wook:_Exploratory_user_interfaces_for_personalized_information_access"><span class="tocnumber">2.8</span> <span class="toctext">February 2, Ahn Jae-wook: Exploratory user interfaces for personalized information access</span></a></li>
</ul>
</li>
<li class="toclevel-1"><a href="#Fall_2010_Speakers"><span class="tocnumber">3</span> <span class="toctext">Fall 2010 Speakers</span></a>
<ul>
<li class="toclevel-2"><a href="#October_20.2C_Kristy_Hollingshead:_Search_Errors_and_Model_Errors_in_Pipeline_Systems"><span class="tocnumber">3.1</span> <span class="toctext">October 20, Kristy Hollingshead: Search Errors and Model Errors in Pipeline Systems</span></a></li>
<li class="toclevel-2"><a href="#October_27.2C_Stanley_Kok:_Structure_Learning_in_Markov_Logic_Networks"><span class="tocnumber">3.2</span> <span class="toctext">October 27, Stanley Kok: Structure Learning in Markov Logic Networks</span></a></li>
<li class="toclevel-2"><a href="#November_1.2C_Owen_Rambow:_Relating_Language_to_Cognitive_State"><span class="tocnumber">3.3</span> <span class="toctext">November 1, Owen Rambow: Relating Language to Cognitive State</span></a></li>
<li class="toclevel-2"><a href="#November_10.2C_Bob_Carpenter:_Whence_Linguistic_Data.3F"><span class="tocnumber">3.4</span> <span class="toctext">November 10, Bob Carpenter: Whence Linguistic Data?</span></a></li>
<li class="toclevel-2"><a href="#November_15.2C_William_Webber:_Information_retrieval_effectiveness:_measurably_going_nowhere.3F"><span class="tocnumber">3.5</span> <span class="toctext">November 15, William Webber: Information retrieval effectiveness: measurably going nowhere?</span></a></li>
<li class="toclevel-2"><a href="#December_8:_Michael_Paul:_Summarizing_Contrastive_Viewpoints_in_Opinionated_Text"><span class="tocnumber">3.6</span> <span class="toctext">December 8: Michael Paul: Summarizing Contrastive Viewpoints in Opinionated Text</span></a></li>
</ul>
</li>
</ul>
</td></tr></table><script type="text/javascript"> if (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); } </script>
<a name="Colloquia" id="Colloquia"></a><h2> <span class="mw-headline"> Colloquia </span></h2>
<p><i>Titles and abstracts appear after the calendar.</i>  Talks are held at 11AM in AV Williams 3258 unless otherwise noted.  All are welcome.  Typically, external speakers have slots for one-on-one meetings with Maryland researchers.  Contact the host if you'd like to have a meeting.
</p><p>If you would like to get on the cl-colloquium@umiacs.umd.edu list, please e-mail <a href="mailto:jessica@cs.umd.edu" class="external text" title="mailto:jessica@cs.umd.edu" rel="nofollow">Jessica Touchard</a>.
</p>
<a name="Google_Calendar_for_CLIP_Speakers" id="Google_Calendar_for_CLIP_Speakers"></a><h3> <span class="mw-headline"> Google Calendar for CLIP Speakers</span></h3>
<p><iframe src="http://www.google.com/calendar/embed?title=CLIP%20Events&amp;src=lqah25nfftkqi2msv25trab8pk%40group.calendar.google.com&amp;color=%23B1440E&amp;height=300&amp;showTitle=1&amp;showNav=1&amp;showDate=1&amp;showTabs=1&amp;showCalendars=1&amp;showPrint=1&amp;showTz=1&amp;wkst=1&amp;hl=en&amp;mode=AGENDA&amp;" width="100%" height="300" frameborder="0" scrolling="no"></iframe>
</p>
<a name="Spring_2011_Speakers" id="Spring_2011_Speakers"></a><h2> <span class="mw-headline"> Spring 2011 Speakers </span></h2>
<a name="April_6.2C_Sinead_Williamson:_Nonparametric_Bayesian_models_for_dependent_data" id="April_6.2C_Sinead_Williamson:_Nonparametric_Bayesian_models_for_dependent_data"></a><h3> <span class="mw-headline"> April 6, Sinead Williamson: Nonparametric Bayesian models for dependent data </span></h3>
<p>A  priori assumptions about the number of parameters required to model
our data are often unrealistic. Bayesian nonparametric models
circumvent this problem by assigning prior mass to a countably
infinite set of parameters, only a finite (but random) number of which
will contribute to a given data set. Over recent years, a number of
authors have presented dependent nonparametric models -- distributions
over collections of random measures associated with values in some
covariate space. While the properties of these random measures are
allowed to vary across the covariate space, the marginal distribution
at each covariate value is given by a known nonparametric
distribution. Such distributions are useful for modelling data that
vary with some covariate: in image segmentation, proximal pixels are
likely to be assigned to the same segment; in modelling documents,
topics are likely to increase and decrease in popularity over time.
</p><p>Most dependent nonparametric models in the literature have Dirichlet
process-distributed marginals. While the Dirichlet process is
undeniably the most commonly used discrete nonparametric Bayesian
prior, this ignores a wide range of interesting models. In my PhD, I
have focused on dependent nonparametric models beyond the Dirichlet
process -- in particular, on dependent nonparametric models based on
the Indian buffet process, a distribution over binary matrices with an
infinite number of columns. In this talk, I will give a general
introduction to dependent nonparametric models, and describe some of
the work I have done in this area.
</p><p>Bio: Sinead Williamson is a PhD student working with Zoubin Ghahramani at
the University of Cambridge, UK. Her main research interests are
dependent nonparametric processes and nonparametric latent variable
models. She will be visiting the University of Maryland for six months
before starting a post doc at Carnegie Mellon University in the Fall.
</p>
<a name="March_30.2C_Sujith_Ravi:_Deciphering_Natural_Language" id="March_30.2C_Sujith_Ravi:_Deciphering_Natural_Language"></a><h3> <span class="mw-headline"> March 30, Sujith Ravi: Deciphering Natural Language </span></h3>
<p>Current research in natural language processing (NLP) relies heavily on supervised techniques, which require labeled training data. But such data does not exist for all languages and domains. Using human annotation to create new resources is not a scalable solution, which raises a key research challenge: How can we circumvent the problem of limited labeled resources for NLP applications?
</p><p>Interestingly, cryptanalysts and archaeologists have tackled similar challenges in the past for solving decipherment problems. Our work draws inspiration from these successes and we present a novel, unified decipherment-based approach for solving natural language problems without labeled (parallel) data. In this talk, we show how NLP problems can be modeled as decipherment tasks. For example, in statistical language translation one can view the foreign-language text as a cipher for English.
</p><p>Combining techniques from classical cryptography and statistical NLP, we then develop novel decipherment methods to tackle a wide variety of problems ranging from letter substitution decipherment to sequence labeling tasks (such as part-of-speech tagging) to language translation. We also introduce novel unsupervised algorithms that explicitly search for minimized models during decipherment and outperform existing state-of-the-art systems on several NLP tasks.
</p><p>Along the way, we show experimental results on several tasks and finally, we demonstrate the first successful attempt at automatic language translation without the use of bilingual resources. Unlike conventional approaches, these decipherment methods can be easily extended to multiple domains and languages (especially resource-poor languages), thereby helping to spread the impact and benefits of NLP research.
</p><p><br />
</p><p>Bio:
</p><p>Sujith Ravi is a Ph.D. candidate in Computer Science at the University of Southern California/Information Sciences Institute, working with Kevin Knight. He received his M.S (2006) degree in Computer Science from USC, and a B.Tech (2004) degree in Computer Science from the National Institute of Technology, Trichy in India. He has also held summer research positions at Google Research and Yahoo Research. His research interests lie in natural language processing, machine learning, computational decipherment and artificial intelligence. His current research focuses on unsupervised and semi-supervised methods with applications in machine translation, transliteration, sequence labeling, large-scale information extraction, syntactic parsing, and information retrieval in discourse. Beyond that, his research experience also includes work on cross-disciplinary areas such as theoretical computer science, computational advertising and computer-aided education. During his graduate student career at USC, he received several awards including an Outstanding Research Assistant Award, an Outstanding Teaching Assistant Award, and an Outstanding Academic Achievement Award.
</p>
<a name="March_16.2C_Mark_Liberman:_Problems_and_opportunities_in_corpus_phonetics" id="March_16.2C_Mark_Liberman:_Problems_and_opportunities_in_corpus_phonetics"></a><h3> <span class="mw-headline"> March 16, Mark Liberman: Problems and opportunities in corpus phonetics </span></h3>
<p>Techniques developed for speech and language technology can now be
applied as research tools in an increasing number of areas, some of
them perhaps unexpected: sociolinguistics, psycholinguistics, language
teaching, clinical diagnosis and treatment, political science -- and
even theoretical phonetics and phonology. Some applications are
straightforward, and the short-term prospects for work in this field
are excellent, but there are many interesting problems for which
satisfactory solutions are not yet available. In contrast to
traditional speech-technology applications areas, in many of these
cases the obvious solutions have not been tried.
</p><p>Bio (from Wikipedia): Mark has a dual appointment at the University of Pennsylvania, as Trustee Professor of Phonetics in the Department of Linguistics, and as a professor in the Department of Computer and Information Sciences. He is the founder and director of the Linguistic Data Consortium.  His main research interests lie in phonetics, prosody, and other aspects of speech communication.  Liberman is also the founder of (and frequent contributor to) Language Log, a blog with a broad cast of dozens of professional linguists. The concept of the eggcorn was first proposed in one of his posts there.
</p>
<a name="March_9.2C_Asad_Sayeed:_Finding_Target-Relevant_Sentiment_Words" id="March_9.2C_Asad_Sayeed:_Finding_Target-Relevant_Sentiment_Words"></a><h3> <span class="mw-headline"> March 9, Asad Sayeed: Finding Target-Relevant Sentiment Words </span></h3>
<p>A major indicator of the presence of an opinion and its polarity are the
words immediately surrounding a potential opinion "target".  But not all
the words near the target are likely to be relevant to finding an
opinion.  Furthermore, prior polarity lexica are only of limited value
in finding these words given corpora in specialized domains such as the
information technology (IT) business press.  There is no ready-made
labeled data for this genre and no existing lexica for domain-specific
polarity words.
</p><p>This implementation-level talk describes some work in progress in
identifying polarity words in an IT business corpus through
crowdsourcing, identifying some of the challenges found in multiple
failed attempts.  We found that annotating at a fine-grained level with
trained individuals is slow, costly, and unreliable given articles that
are sometimes quite long.   In order to crowdsource the task, however,
we had to find ways to ask the question that do not require the user to
think too hard about exactly what an opinion is and to reduce the
propensity to cheat on a difficult question.
</p><p>We built an CrowdFlower-based interface that uses a drag-and-drop
process to classify words in context.  We will demonstrate the interface
during the talk and show samples of the results, which we are still in
the process of gathering.  We will also show some of the
implementation-level challenges of adapting the CrowdFlower interface to
a non-standard UI paradigm.
</p><p>If there is time, we will also discuss one of the ways in which we plan
to use the data through a CRF-based model of the syntactic relationship
between sentiment words and target mentions which we developed in
FACTORIE and Scala."
</p><p>Bio:
"Asad Sayeed is a PhD candidate in computer science and member of the University of Maryland CLIP lab.  He is working on his dissertation in syntactically fine-grained sentiment analysis."
</p>
<a name="March_2.2C_Ned_Talley:_An_Unsupervised_View_of_NIH_Grants_-_Latent_Categories_and_Clusters_in_an_Interactive_Format" id="March_2.2C_Ned_Talley:_An_Unsupervised_View_of_NIH_Grants_-_Latent_Categories_and_Clusters_in_an_Interactive_Format"></a><h3> <span class="mw-headline"> March 2, Ned Talley: An Unsupervised View of NIH Grants - Latent Categories and Clusters in an Interactive Format </span></h3>
<p>The U.S. National Institutes of Health (NIH) consists of twenty-five Institutes and Centers that award ~80,000 grants each year.  The Institutes have distinct missions and research priorities, but there is substantial overlap in the types of research they support, which creates a funding landscape that can be difficult for researchers and research policy professionals to navigate. We have created a publicly accessible database (<a href="https://app.nihmaps.org" class="external free" title="https://app.nihmaps.org" rel="nofollow">https://app.nihmaps.org</a>) in which NIH grants are topic modeled using Latent Dirichlet Allocation, and are clustered using a force-directed algorithm for placing grants as nodes in two dimensional space, where they can be accessed in an online map-like format.
</p><p>Ned Talley is an NIH Program Director who manages grants on synaptic transmission, synaptic plasticity, and advanced microscopy and imaging.  For the past two years he has also been focused on NIH grants informatics, in order to address unmet needs at NIH, and to match these needs with burgeoning technologies in artificial intelligence, information retrieval, and information visualization.  He has directed this project through collaborations with investigators from University of Southern California, UC Irvine, Indiana University, and University of Massachusetts.
</p>
<a name="February_16.2C_Ophir_Frieder:_Humane_Computing" id="February_16.2C_Ophir_Frieder:_Humane_Computing"></a><h3> <span class="mw-headline"> February 16, Ophir Frieder: Humane Computing </span></h3>
<p>Humane Computing is the design, development, and implementation of computing systems that directly focus on improving the human condition or experience.  In that light, three efforts are presented, namely, improving foreign name search technology, spam detection algorithms for peer-to-peer file sharing systems, and novel techniques for urinary tract infection treatment.
</p><p>The first effort is in support of the Yizkor Books project of the Archives Section of the United States Holocaust Memorial Museum.  Yizkor Books are commemorative, firsthand accounts of communities that perished before, during, and after the Holocaust.  Users of such volumes include historians, archivists, educators, and survivors.  Since Yizkor collections are written in 13 different languages, searching them is difficult.   In this effort, novel foreign name search approaches which favorably compare against the state of the art are developed.  By segmenting names, fusing individual results, and filtering via a threshold, our approach statistically significantly improves on traditional Soundex and n-gram based search techniques used in the search of such texts.  Thus, previously unsuccessful searches are now supported.
</p><p>In the second effort, spam characteristics in peer-to-peer file sharing systems are determined.  Using these characteristics, an approach that does not rely on external information or user feedback is developed.  Cost reduction techniques are employed resulting in a statistically significant reduction of spam.  Thus, the user search experience is improved.
</p><p>Finally, a novel “self start”, patient-specific approach for the treatment of recurrent urinary tract infections is presented.  Using conventional data mining techniques, an approach that improves patient care, reduces bacterial mutation, and lowers treatment cost is presented.  Thus, an approach that provides better, in terms of patient comfort, quicker, in terms of outbreak duration, and more economical care for female patients that suffer from recurrent urinary tract infections is described.
</p><p><br />
Biography
Ophir Frieder is the Robert L. McDevitt, K.S.G., K.C.H.S. and Catherine H. McDevitt L.C.H.S. Chair in Computer Science and Information Processing and is Chair of the Department of Computer Science at Georgetown University. His research interests focus on scalable information retrieval systems spanning search and retrieval and communications issues.  He is a Fellow of the AAAS, ACM, and IEEE.
</p>
<a name="February_9.2C_Naomi_Feldman:_Using_a_developing_lexicon_to_constrain_phonetic_category_acquisition" id="February_9.2C_Naomi_Feldman:_Using_a_developing_lexicon_to_constrain_phonetic_category_acquisition"></a><h3> <span class="mw-headline"> February 9, Naomi Feldman: Using a developing lexicon to constrain phonetic category acquisition </span></h3>
<p>Variability in the acoustic signal makes speech sound category
learning a difficult problem.  Despite this difficulty, human learners
are able to acquire phonetic categories at a young age, between six
and twelve months.  Learners at this age also show evidence of
attending to larger units of speech, particularly in word segmentation
tasks.  This work investigates how word-level information can help
make the phonetic category learning problem easier.  A hierarchical
Bayesian model is constructed that learns to categorize speech sounds
and words simultaneously from a corpus of segmented acoustic tokens.
No lexical information is given to the model a priori; it is simply
allowed to begin learning a set of word types at the same time that it
learns to categorize speech sounds.  Simulations compare this model to
a purely distributional learner that does not have feedback from a
developing lexicon.  Results show that whereas a distributional
learner mistakenly merges several sets of overlapping categories, an
interactive model successfully disambiguates these categories.  An
artificial language learning experiment with human learners
demonstrates that people can make use of the type of word-level cues
required for interactive learning.  Together, these results suggest
that phonetic category learning can be better understood in
conjunction with other contemporaneous learning processes and that
simultaneous learning of multiple layers of linguistic structure can
potentially make the language acquisition problem more tractable.
</p><p>Bio: Naomi was a graduate student in the Department of Cognitive and Linguistic Sciences at Brown University working with Jim Morgan and Tom Griffiths. She's interested in speech perception and language acquisition, especially the relationship between phonetic category learning, phonological development, and perceptual changes during infancy.  In January 2011, she became an assistant professor in the Department of Linguistics at the University of Maryland.
</p>
<a name="February_2.2C_Ahn_Jae-wook:_Exploratory_user_interfaces_for_personalized_information_access" id="February_2.2C_Ahn_Jae-wook:_Exploratory_user_interfaces_for_personalized_information_access"></a><h3> <span class="mw-headline"> February 2, Ahn Jae-wook: Exploratory user interfaces for personalized information access </span></h3>
<p>Personalized information access systems aim to provide tailored information to users according to their various tasks, interests, or contexts.  They have long been relied on the ability of algorithms for estimating user interests and generating personalized information.  They observe user behaviors, build mental models of the users, and apply the user model for customizing the information.  This process can be done even without any explicit user intervention.  However, we can add users into the loop of the personalization process, so that the systems can catch user interests even more precisely and the users can flexibly control the behavior of the systems.
</p><p>In order to exploit the benefits of the user interfaces for personalized information access, we have investigated various aspects of exploratory information access systems.  Exploratory information access systems can combine the strengths of algorithms and user interfaces.  Users can learn and investigate their information need beyond the simple lookup search strategy.  By adding the idea of the exploration to the personalized information access, we could devise advanced user interfaces for the personalization.  Specifically, we have tried to understand how we could let users learn, manipulate, and control the core component of many personalized systems, user models.  In this presentation, I am going to introduce several ideas about how to present and control user models using different user interfaces.  The example studies include open/editable user model, tab-based user model and query control, reference point-based visualization that incorporates the user model and the query spaces, and named-entity based searching/browsing user interface.  The results and the lessons of the user studies are discussed.
</p><p>Bio: Jae-wook Ahn has recently defended his Ph.D. dissertation at the School of Information Sciences, University of Pittsburgh in September 2010.  He has worked with his Ph.D. mentor Dr. Peter Brusilovsky and Dr. Daqing He.  He is currently a research associate of the Department of Computer Science and the Human Computer Interaction Lab, working with Dr. Ben Shneiderman.
</p>
<a name="Fall_2010_Speakers" id="Fall_2010_Speakers"></a><h2> <span class="mw-headline"> Fall 2010 Speakers </span></h2>
<ul><li> Roger Levy
</li><li> Earl Wagner
</li><li> Eugene Charniak
</li><li> Dave Newman
</li><li> Ray Mooney
</li></ul>
<a name="October_20.2C_Kristy_Hollingshead:_Search_Errors_and_Model_Errors_in_Pipeline_Systems" id="October_20.2C_Kristy_Hollingshead:_Search_Errors_and_Model_Errors_in_Pipeline_Systems"></a><h3> <span class="mw-headline"> October 20, Kristy Hollingshead: Search Errors and Model Errors in Pipeline Systems </span></h3>
<p>Pipeline systems, in which data is sequentially processed in stages with the output of one stage providing input to the next, are ubiquitous in the field of natural language processing (NLP) as well as many other research areas. The popularity of the pipeline system architecture may be attributed to the utility of pipelines in improving scalability by reducing search complexity and increasing efficiency of the system. However, pipelines can suffer from the well-known problem of "cascading errors," where errors earlier in the pipeline propagate to later stages in the pipeline. In this talk I will make a distinction between two different type of cascading errors in pipeline systems. The first I will term "search errors," where there exists a higher-scoring candidate (according to the model), but that candidate has been excluded from the search space. The second type of error that I will address might be termed "model errors," where the highest-scoring candidate (according to the model) is not the best candidate (according to some gold standard). Statistical NLP models are imperfect by nature, resulting in model errors. Interestingly, the same pipeline framework that causes search errors can also resolve (or work around) model errors; in this talk I will demonstrate several techniques for detecting and resolving search and model errors, which can result in improved efficiency with no loss in accuracy. I will briefly mention the technique of pipeline iteration, introduced in my ACL'07 paper, and introduce some related results from my dissertation. I will then focus on work done with my PhD advisor Brian Roark on chart cell constraints, as published in our COLING'08 and NAACL'09 papers; this work provably reduces the complexity of a context-free parser to quadratic performance in the worst case (observably linear) with a slight gain in accuracy using the Charniak parser. While much of this talk will be on parsing pipelines, I am currently extending some of this work to MT pipelines and would welcome discussion along those lines.
</p><p>Kristy Hollingshead earned her PhD in Computer Science and Engineering this year, from the Center for Spoken Language Understanding (CSLU) at the Oregon Health &amp; Science University (OHSU). She received her B.A. in English-Creative Writing from the University of Colorado in 2000 and her M.S. in Computer Science from OHSU in 2004. Her research interests in natural language processing include parsing, machine translation, evaluation metrics, and assistive technologies. She is also interested in general techniques on improving system efficiency, to allow for richer contextual information to be extracted for use in downstream stages of a pipeline system. Kristy was a National Science Foundation Graduate Research Fellow from 2004-2007.
</p>
<a name="October_27.2C_Stanley_Kok:_Structure_Learning_in_Markov_Logic_Networks" id="October_27.2C_Stanley_Kok:_Structure_Learning_in_Markov_Logic_Networks"></a><h3> <span class="mw-headline"> October 27, Stanley Kok: Structure Learning in Markov Logic Networks </span></h3>
<p>Statistical learning handles uncertainty in a robust and principled way.
Relational learning (also known as inductive logic programming)
models domains involving multiple relations. Recent years have seen a
surge of interest in the statistical relational learning (SRL) community
in combining the two, driven by the realization that many (if not most)
applications require both and by the growing maturity of the two fields.
</p><p>Markov logic networks (MLNs) is a statistical relational model that has
gained traction within the AI community in recent years because of its
robustness to noise and its ability to compactly model complex domains.
MLNs combine probability and logic by attaching weights to first-order
formulas, and viewing these as templates for features of Markov networks.
Learning the structure of an MLN consists of learning both formulas and
their weights.
</p><p>To obtain weighted MLN formulas, we could rely on human experts
to specify them. However, this approach is error-prone and requires
painstaking knowledge engineering. Further, it will not work on domains
where there is no human expert. The ideal solution is to automatically
learn MLN structure from data. However, this is a challenging task because
of its super-exponential search space. In this talk, we present a series of
algorithms that efficiently and accurately learn MLN structure.
</p>
<a name="November_1.2C_Owen_Rambow:_Relating_Language_to_Cognitive_State" id="November_1.2C_Owen_Rambow:_Relating_Language_to_Cognitive_State"></a><h3> <span class="mw-headline"> November 1, Owen Rambow: Relating Language to Cognitive State </span></h3>
<p>In the 80s and 90s of the last century, in subdisciplines such as planning,
text generation, and dialog systems, there was considerable interest in
modeling the cognitive states of interacting autonomous agents.  Theories
such as Speech Act Theory (Austin 1962), the belief-desire-intentions model
of Bratman (1987), and Rhetorical Structure Theory (Mann and Thompson 1988)
together provide a framework in which to link cognitive state with language
use.  However, in general natural language processing (NLP), little use was
made of such theories, presumably because of the difficulty at the time of
some underlying tasks (such as syntactic parsing).  In this talk, I propose
that it is time to again think about the explicit modeling of cognitive
state for participants in discourse.  In fact, that is the natural way to
formulate what NLP is all about.  The perspective of cognitive state can
provide a context in which many disparate NLP tasks can be classified and
related.  I will present two NLP projects at Columbia which relate to the
modeling of cognitive state:
</p><p>Discourse participants need to model each other's cognitive states, and
language makes this possible by providing special morphological, syntactic,
and lexical markers.  I present results in automatically determining the
degree of belief of a speaker in the propositions in his or her utterance.
</p><p>Bio: PhD from University of Pennsylvania, 1994, working on German syntax.
My office mate was Philip Resnik.  I worked at CoGentex, Inc (a small
company) and AT&amp;T Labs -- Research until 2002, and since then at Columbia as
a Research Scientist.  My research interests cover both the nuts-and-bolts
of languages, specifically syntax, and how language is used in context.
</p>
<a name="November_10.2C_Bob_Carpenter:_Whence_Linguistic_Data.3F" id="November_10.2C_Bob_Carpenter:_Whence_Linguistic_Data.3F"></a><h3> <span class="mw-headline"> November 10, Bob Carpenter: Whence Linguistic Data?  </span></h3>
<p>The empirical approach to linguistic theory involves collecting
data and annotating it according to a coding standard.  The
ability of multiple annotators to consistently annotate new
data reflects the applicability of the theory.    In this
talk, I'll introduce a generative probabilistic model of the
annotation process for categorical data.  Given a collection of
annotated data, we can infer the true labels of items, the prevalence
of some phenomenon (e.g. a given intonation or syntactic alternation),
the accuracy and category bias of each annotator, and the codability
of the theory as measured by the mean accuracy and bias of annotators
and their variability.  Hierarchical model extensions allow us to
model item labeling difficulty and take into account annotator
background and experience.  I'll demonstrate the efficacy of the
approach using expert and non-expert pools of annotators for simple
linguistic labeling tasks such as textual inference, morphological
tagging, and named-entity extraction.  I'll discuss applications
such as monitoring an annotation effort, selecting items with active
learning, and generating a probabilistic gold standard for machine
learning training and evaluation.
</p>
<a name="November_15.2C_William_Webber:_Information_retrieval_effectiveness:_measurably_going_nowhere.3F" id="November_15.2C_William_Webber:_Information_retrieval_effectiveness:_measurably_going_nowhere.3F"></a><h3> <span class="mw-headline"> November 15, William Webber: Information retrieval effectiveness: measurably going nowhere? </span></h3>
<p>Information retrieval works by heuristics; correctness cannot be
formally proved, but must be empirically assessed.  Test
collections make this evaluation automated and repeatable.
Collection-based evaluation has been standard for half a century.
The IR community prides itself on the rigour of the
experimental tradition that has been built upon this
foundation;  it is notoriously difficult to publish in the
field without a thorough experimental validation.  No
attention, however, has been paid to the question of whether
methodological rigour in evaluation has to verifiable.  In
this talk, we present a survey of retrieval results published
over the past decade, which fails to find evidence that
retrieval effectiveness is in fact improving.  Rather, each 
experiment's impressive leap forward is preceded by a few 
careful steps back.
</p><p>Bio:
</p><p>William Webber is a Research Associate in the Department of Computer
Science and Software Engineering at the University of Melbourne,
Australia.  He has recently completed his PhD thesis, "Measurement in
Information Retrieval Evaluation", under the supervision of Professors
Alistair Moffat and Justin Zobel.
</p>
<a name="December_8:_Michael_Paul:_Summarizing_Contrastive_Viewpoints_in_Opinionated_Text" id="December_8:_Michael_Paul:_Summarizing_Contrastive_Viewpoints_in_Opinionated_Text"></a><h3> <span class="mw-headline"> December 8: Michael Paul: Summarizing Contrastive Viewpoints in Opinionated Text </span></h3>
<p>Performing multi-document summarization of opinionated text has unique
challenges because it is important to recognize that the same information
may be presented in different ways from different viewpoints. In this talk,
we will present a special kind of contrastive summarization approach
intended to highlight this phenomenon and to help users digest conflicting
opinions. To do this, we introduce a new graph-based algorithm, Comparative
LexRank, to score sentences in a summary based on a combination of both
representativeness of the collection and comparability between opposing
viewpoints. We then address the issue of how to automatically discover and
extract viewpoints from unlabeled text, and we experiment with a novel
two-dimensional topic model for the task of unsupervised clustering of
documents by viewpoint. Finally, we discuss how these two stages can be
combined to both automatically extract and summarize viewpoints in an
interesting way. Results are presented on two political opinion data sets.
</p><p>This project was joint work with ChengXiang Zhai and Roxana Girju.
</p><p>Bio:
Michael Paul is a first-year Ph.D. student of Computer Science at the Johns
Hopkins University and a member of the Center for Language and Speech
Processing. He earned a B.S. from the University of Illinois at
Urbana-Champaign in 2009. He is currently a Graduate Research Fellow of the
National Science Foundation and a Dean's Fellow of the Whiting School of
Engineering.
</p>
<!-- 
NewPP limit report
Preprocessor node count: 25/1000000
Post-expand include size: 35/2097152 bytes
Template argument size: 0/2097152 bytes
Expensive parser function count: 0/100
-->

<!-- Saved in parser cache with key umiacs-clip_:pcache:idhash:6-0!1!0!!en!2!edit=0 and timestamp 20110403003627 -->
<div class="printfooter">
Retrieved from "<a href="https://wiki.umiacs.umd.edu/clip/index.php/Events">https://wiki.umiacs.umd.edu/clip/index.php/Events</a>"</div>
						<!-- end content -->
						<div class="visualClear"></div>
		</div>
	</div>
		</div>
	<!-- end of gumax-content-body -->
	<div class="gumax-footer-spacer"></div>
		<!-- gumax-content-actions -->
		<div id="gumax-content-actions">
		<ul>

			 <li id="ca-nstab-main" class="selected"><a href="/clip/index.php/Events" title="View the content page [c]" accesskey="c">Page</a></li>
			 <li id="ca-talk" class="new"><a href="/clip/index.php?title=Talk:Events&amp;action=edit&amp;redlink=1" title="Discussion about the content page [t]" accesskey="t">Discussion</a></li>
			 <li id="ca-viewsource"><a href="/clip/index.php?title=Events&amp;action=edit" title="This page is protected.&#10;You can view its source [e]" accesskey="e">View source</a></li>
			 <li id="ca-history"><a href="/clip/index.php?title=Events&amp;action=history" title="Past versions of this page [h]" accesskey="h">History</a></li>		</ul>
		<div class="gumax-message">This page was last modified on 24 March 2011 at 22:21 &#8226;&#8226;&#8226;  and has been viewed 1,893 times</div>
	</div>
		<!-- end of gumax-content-actions -->


	<!-- ///// gumax-footer ///// -->
	<div id="gumax-footer">

			<!-- personal tools  -->
	<div id="gumax-personal-tools">
		<h5>Toolbox</h5>
		<ul>
				<li id="t-whatlinkshere"><a href="/clip/index.php/Special:WhatLinksHere/Events" title="List of all wiki pages that link here [j]" accesskey="j">What links here</a></li>
				<li>&#47;</li>
				<li id="t-recentchangeslinked"><a href="/clip/index.php/Special:RecentChangesLinked/Events" title="Recent changes in pages linked from this page [k]" accesskey="k">Related changes</a></li>
				<li>&#47;</li>
<li id="t-specialpages"><a href="/clip/index.php/Special:SpecialPages" title="List of all special pages [q]" accesskey="q">Special pages</a></li>
				<li>&#47;</li>
				<li id="t-print"><a href="/clip/index.php?title=Events&amp;printable=yes" title="Printable version of this page [p]" accesskey="p">Printable version</a></li>				<li>&#47;</li>
				<li id="t-permalink"><a href="/clip/index.php?title=Events&amp;oldid=355" title="Permanent link to this version of the page">Permanent link</a></li>		</ul>
	</div>
	<!-- end of personal tools  -->

			<!-- gumax-f-list -->
	<div id="gumax-f-list">
		<ul>
						<li id="f-poweredby"><a href="http://mediawiki.org" target="_blank">Powered by MediaWiki</a></li>
		</ul>
	</div>
	<!-- end of gumax-f-list -->

	</div>
	<!-- ///// end of gumax-footer ///// -->


</div>
<!-- ===== end of gumax-page ===== -->

	</td><td id="gumax-page-table-right"><img src="/clip/skins/gumax/blank.gif" alt="" /></td></tr></table>
	<!--[if lt IE 7]>
		<script type="text/javascript">pngfix('td');</script>
	<![endif]-->

</div>
<!-- ##### end of gumax-wrapper ##### -->



		<script type="text/javascript">if (window.runOnloadHook) runOnloadHook();</script>
<!-- Served in 0.341 secs. --></body></html>





